<!DOCTYPE html><html lang="en" data-astro-cid-bvzihdzo> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Automation Rhapsody" href="https://automationrhapsody.com/rss.xml"><meta name="generator" content="Astro v5.5.3"><script src="/scripts.js"></script><!-- Font preloads --><link rel="stylesheet" property="stylesheet" href="https://fonts.googleapis.com/css?family=Playball"><link rel="stylesheet" property="stylesheet" href="https://fonts.googleapis.com/css?family=Bitter:400,400italic,700"><link rel="preconnect" href="https://fonts.googleapis.com"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100..900;1,100..900&display=swap" rel="stylesheet"><!-- Canonical URL --><link rel="canonical" href="https://automationrhapsody.com/performance-testing-with-gatling-reports/"><!-- Primary Meta Tags --><title>Performance testing with Gatling - reports</title><meta name="title" content="Performance testing with Gatling - reports"><meta name="description" content="Some details on Gatling results report."><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://automationrhapsody.com/performance-testing-with-gatling-reports/"><meta property="og:title" content="Performance testing with Gatling - reports"><meta property="og:description" content="Some details on Gatling results report."><meta property="og:image" content="https://automationrhapsody.com/blog-placeholder.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://automationrhapsody.com/performance-testing-with-gatling-reports/"><meta property="twitter:title" content="Performance testing with Gatling - reports"><meta property="twitter:description" content="Some details on Gatling results report."><meta property="twitter:image" content="https://automationrhapsody.com/blog-placeholder.jpg"><style>:root{--color-gray-bg: #f5f5f5;--color-gray-text: #5e5e5e}body{font-family:Roboto,sans-serif;background:var(--color-gray-bg);word-wrap:break-word;overflow-wrap:break-word;color:var(--color-gray-text);font-size:18px}main{width:960px;max-width:100%;margin:auto}h2{color:#3879d9;font-size:20px;margin:25px 0 6px}p{margin:6px 0}img{max-width:100%}pre{margin:0;padding:12px}.card{padding:16px;margin:10px;box-shadow:0 2px 3px #acabab;background:#fff;border-radius:24px;color:inherit}@media (max-width: 720px){body{font-size:16px}ul{padding-inline-start:16px}}.tab{overflow:hidden;border:1px solid #ccc;background-color:#f1f1f1}.tab button{background-color:inherit;float:left;border:none;outline:none;cursor:pointer;padding:14px 16px;transition:.3s}.tab button:hover{background-color:#ddd}.tab button.active{background-color:#ccc}.tabcontent{display:none;border-top:none}footer[data-astro-cid-sz7xmlte]{margin:24px 0;text-align:center}header[data-astro-cid-3ef6ksr2]{text-align:center;font-size:56px}header[data-astro-cid-3ef6ksr2] div[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{font-family:Playball,Arial;color:#000;text-decoration:none;text-shadow:0 .033em 0 #fff;border-bottom:none}
.post-title[data-astro-cid-bvzihdzo]{font-family:Bitter,serif;font-weight:700!important;margin:0;padding:5px 0;font-size:32px;line-height:40px;color:#444}.tags[data-astro-cid-bvzihdzo]{display:flex;flex-wrap:wrap}.tags[data-astro-cid-bvzihdzo]>a[data-astro-cid-bvzihdzo]{margin-left:8px}@media (max-width: 720px){article[data-astro-cid-bvzihdzo]{padding:12px}}
</style></head> <body data-astro-cid-bvzihdzo> <header data-astro-cid-3ef6ksr2> <div data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2>Automation Rhapsody</a> </div> </header>  <main data-astro-cid-bvzihdzo> <article class="card" data-astro-cid-bvzihdzo> <div class="prose" data-astro-cid-bvzihdzo> <div class="title" data-astro-cid-bvzihdzo> <h1 class="post-title" data-astro-cid-bvzihdzo>Performance testing with Gatling - reports</h1> <div class="date" data-astro-cid-bvzihdzo> <time datetime="2015-11-13T00:00:00.000Z"> Nov 13, 2015 </time> </div> <hr data-astro-cid-bvzihdzo> </div>  <p>Current post is part of <a href="/performance-testing-with-gatling/">Performance testing with Gatling</a> series in which Gatling performance testing tool is explained in details.</p>
<p>If you have followed the Gatling series so far you should know how to record a simulation, what simulation consists of, how to create Maven project and make code well structured and maintainable. Now is the time to run that code and see the results.</p>
<h2>Gatling global information</h2>
Gatling has a pretty cool looking report. It shows global information about simulation as long as more detailed information for each request or request group. This is how the global information looks like:
<p><a href="/images/2015/11/Gatling-reports-global.png"><img src="/images/2015/11/Gatling-reports-global.png" alt="Gatling-reports-global"></a></p>
<p>Shown above is just part of global information report page. There are following sections on it:</p>
<ul>
 	<li><strong>Indicators</strong> - distribution in specified response time intervals: less than 800ms, 800ms - 1200ms, more 1200ms and failed. This can give you a general overview of the system performance. If the highest percentage of the responses are less than 800ms this is quite good performance indication.</li>
 	<li><strong>Number of requests</strong> - pie chart showing different request types. This gives visual information how many requests of different type are being sent. Type is actually the request name defined in <em><strong>http()</strong></em> method.</li>
 	<li><strong>STATISTICS</strong> - table with very detailed information what count of each request type has been sent, OK, KO count, KO percentage. There is information what is the best, worst and mean time for each request type. Since worst time could be for a single response this is not quite informative. This is why there is grouping what is the response time for 95% and 99% of the responses. Last information requests per second.</li>
 	<li><strong>Active Users along the Simulation</strong> - how many virtual users were sending requests at each moment during the simulation. There is also user count per scenario. The scenario is identified by its name defined in <em><strong>scenario()</strong></em> method.</li>
 	<li><strong>Response Time Distribution</strong> - detailed responses distribution in small time intervals. Pretty similar to <em><strong>Indicators</strong></em> one, but much more detailed, as time intervals are very small. This gives a much better perspective of performance as you can see what percentage of the requests are in given time bucket. This graphic also includes error requests as well.</li>
 	<li><strong>Response Time Percentiles over Time (OK)</strong> - minimum and maximum request time at each moment during simulation only for successful (OK) requests. There is also request grouping into percentage values showing what percent of the requests take given amount of time. Similar to <strong>STATISTICS</strong> table, but here there is much more detailed grouping and also you can see it distributed during simulation execution. Additionally, this graphic shows the number of user at each moment during simulation.</li>
 	<li><strong>Number of requests per second</strong> - how many requests are done to the server at each moment during simulation. There is separate graphics for all requests, OK and KO requests. Additionally, this graphic shows the number of user at each moment during simulation.</li>
 	<li><strong>Number of responses per second</strong> - how many responses are done to the server at each moment during simulation. There is separate graphics for all responses, OK and KO responses. Additionally, this graphic shows the number of user at each moment during simulation.</li>
</ul>
<h2>Gatling request details</h2>
Apart from the global information, there is a detailed report for each request type. Requests are sorted by name, used when defining the HTTP request in <em><strong>http()</strong></em> method. This is how request details look like:
<p><a href="/images/2015/11/Gatling-reports-details.png"><img src="/images/2015/11/Gatling-reports-details.png" alt="Gatling-reports-details"></a></p>
<p>Shown above is just part of the request details report page. There are following sections on it:</p>
<ul>
 	<li><strong>Indicators</strong> - same as in global information</li>
 	<li><strong>STATISTICS</strong> - same as in global information but just timing for this particular request are shown.</li>
 	<li><strong>Response Time Distribution</strong> - same as in global information</li>
 	<li><strong>Response Time Percentiles over Time (OK)</strong> - same as in global information</li>
 	<li><strong>Latency Percentiles over Time (OK)</strong> - same as <strong>Response Time Percentiles over Time (OK)</strong>, but showing the time needed for the server to process the request, although it is incorrectly called latency. By definition Latency + Process Time = Response time. So this graphic is supposed to give the time needed for a request to reach the server. Checking real-life graphics I think this graphic shows not the Latency, but the real Process Time. You can get an idea of the real Latency by taking one and the same second from Response Time Percentiles over Time (OK) and subtract values from current graphs for the same second.</li>
 	<li><strong>Number of requests per second</strong> - same as in global information</li>
 	<li><strong>Number of responses per second</strong> - same as in global information</li>
 	<li><strong>Response Time against Global RPS</strong> - distribution of current request's response time related to total request per second of the simulation.</li>
 	<li><strong>Latency against Global RPS</strong> - distribution of current request's latency (process time) related to total request per second of the simulation.</li>
</ul>
<h2>Gatling data in simulation.log file</h2>
As you will see in the previous two sections Gatling gathers a limited amount of data, how many requests are made per any given time of the execution, are the responses OK or KO, what time each request and response take. All this information is stored into simulation.log file. Although the file is plain text data in it is understandable only by Gatling. In <a href="/performance-testing-with-gatling-tips-and-tricks-for-advanced-usage/">Performance testing with Gatling – advanced usage</a> post, it is shown how you can extract more details from request and response. This gets recorded in simulation.log file, so be careful when doing this as this file might get enormous. View sample <a href="/examples/Gatling-report/simulation.log.txt" target="_blank" rel="noopener">simulation.log</a> file or sample <a href="/examples/Gatling-report/index.html" target="_blank" rel="noopener">Gatling report</a>.
<h2>Conclusion</h2>
Gatling report is a valuable source of information to read the performance data by providing some details about requests and responses timing. The report should not be your main tool for finding issues when doing performance testing though. It is a good idea to have a server monitoring tool that gives more precise information about memory consumption and CPU. In case of bottlenecks identified by Gatling, it is mandatory to do some profiling of the application to understand what action on the server takes the longest time.  <hr data-astro-cid-bvzihdzo>  <h2 data-astro-cid-bvzihdzo>Related Posts</h2> <ul data-astro-cid-bvzihdzo> <li data-astro-cid-bvzihdzo> <a href="/performance-testing-with-gatling/" data-astro-cid-bvzihdzo>Performance testing with Gatling</a> </li> </ul>  <div class="tags" data-astro-cid-bvzihdzo> <div data-astro-cid-bvzihdzo>Tags:</div> <a href="/tags/gatling" data-astro-cid-bvzihdzo>Gatling</a><a href="/tags/non-functional" data-astro-cid-bvzihdzo>Non-functional</a><a href="/tags/performance" data-astro-cid-bvzihdzo>Performance</a><a href="/tags/tutorials" data-astro-cid-bvzihdzo>Tutorials</a> </div> </div> </article> </main> <footer data-astro-cid-sz7xmlte>
&copy; 2025 - Automation Rhapsody. All rights reserved.
</footer>  </body></html>